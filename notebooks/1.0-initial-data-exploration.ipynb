{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nova Financial Solutions - Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Cleaning\n",
    "\n",
    "In this section, we have imported several functions from the `shared` module to load and clean the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.dataset_loader import load_raw_dataset\n",
    "from shared.data_cleaning import (\n",
    "     date_to_datetime,\n",
    "     handle_missing_values, \n",
    "     standardize_text,\n",
    "     handle_duplicates,\n",
    "     save_processed_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Raw Data\n",
    "First, we need to load the raw dataset using the `load_raw_dataset` function. This function loads the data from a CSV file and returns a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_raw_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert date to datetime\n",
    "This function takes the raw dataset as input and converts any date columns to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = date_to_datetime(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing values\n",
    "The `handle_missing_values` function handles missing values in the dataset. It Drop rows with empty headline, url, date, stock columns and Replace empty row publisher column with Unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the handle_missing_values function on the processed dataset\n",
    "processed_data = handle_missing_values(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize text\n",
    "The `standardize_text` function is used to standardize text data in the dataset. It performs tasks such as converting text to lowercase, removing special characters or punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the standardize_text function on the processed dataset\n",
    "processed_data = standardize_text(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle duplicates\n",
    "The `handle_duplicates` function deals with duplicate records in the dataset. It Check for duplicate rows based on the url column & Keep only the row with the latest date compared to all duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the handle_duplicates function on the processed dataset\n",
    "processed_data = handle_duplicates(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save processed dataset\n",
    "The `save_processed_dataset` function allows to save the cleaned and preprocessed dataset to a CSV file. Create the output folder if it doesn't exist and Save the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "output_folder = os.path.join('..', 'data', 'processed') \n",
    "save_processed_dataset(processed_data, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistical Data Analysis\n",
    "\n",
    "In this section, we define functions that perform Descriptive statistical data analysis tasks on a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Text length stats\n",
    "\n",
    "This function calculates various statistics related to the length of the headlines in the given dataset. It takes the dataset as input and returns a dictionary with the following statistics:\n",
    "\n",
    "- `mean`: The mean length of the headlines.\n",
    "- `median`: The median length of the headlines.\n",
    "- `minimum`: The minimum length of the headlines.\n",
    "- `maximum`: The maximum length of the headlines.\n",
    "- `standard_deviation`: The standard deviation of the lengths of the headlines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_length_stats(data):\n",
    " \n",
    "    headline_lengths = data['headline'].str.len()\n",
    "    stats = {\n",
    "        'mean': headline_lengths.mean(),\n",
    "        'median': headline_lengths.median(),\n",
    "        'minimum': headline_lengths.min(),\n",
    "        'maximum': headline_lengths.max(),\n",
    "        'standard_deviation': headline_lengths.std()\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inferential Statistical Data Analysis\n",
    "\n",
    "In this section, we define functions that perform Inferential statistical data analysis tasks on a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `get_text_length_stats(data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
